{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Project layout 1 2 3 4 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Welcome to MkDocs"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Commands"},{"location":"#project-layout","text":"1 2 3 4 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"bind-mounts/","text":"Using Bind Mounts Bind mounts allow web servers to automatically detect changes made to source code and apply them immediately. For this example, we will run a Jekyll webserver as a container ontop of a code base - if anything in the code base is changed, it should reflect immediately on the webpage 1 2 3 git clone https://github.com/BretFisher/udemy-docker-mastery cd udemy-docker-mastery/bindmount-sample-1/ docker run -p 80 :4000 -v $( pwd ) :/site bretfisher/jekyll-serve","title":"Bind Mounts for Automatic Updates"},{"location":"bind-mounts/#using-bind-mounts","text":"Bind mounts allow web servers to automatically detect changes made to source code and apply them immediately. For this example, we will run a Jekyll webserver as a container ontop of a code base - if anything in the code base is changed, it should reflect immediately on the webpage 1 2 3 git clone https://github.com/BretFisher/udemy-docker-mastery cd udemy-docker-mastery/bindmount-sample-1/ docker run -p 80 :4000 -v $( pwd ) :/site bretfisher/jekyll-serve","title":"Using Bind Mounts"},{"location":"docker-compose-builds/","text":"Adding custom images to docker-compose files For this example we will create a custom dockerfile which builds a drupal image. This build file will then be included into our docker-compose file in order to spin it up 1 2 3 4 5 6 7 FROM drupal:8 RUN apt-get update && apt-get install -y git \\ && rm -rf /var/lib/apt/lists/* WORKDIR /var/www/html/themes RUN git clone --branch 8 .x-3.x --single-branch --depth 1 https://git.drupal.org/project/bootstrap.git \\ && chown -R www-data:www-data bootstrap WORKDIR /var/www/html Then add this docker file to docker-compose 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 version : \"2\" services : drupal : image : custom-drupal build : . ports : - 8080:80 volumes : - modeuls:/var/www/html/modules - profiles:/var/www/html/profiles - themes:/var/www/html/themes - sites:/var/www/html/sites postgres : image : postgres:latest environment : - POSTGRES_PASSWORD=example volumes : - drupal-data:/var/lib/postgresql/data volumes : modeuls : profiles : themes : sites : drupal-data :","title":"Build in Docker Compose"},{"location":"docker-compose-builds/#adding-custom-images-to-docker-compose-files","text":"For this example we will create a custom dockerfile which builds a drupal image. This build file will then be included into our docker-compose file in order to spin it up 1 2 3 4 5 6 7 FROM drupal:8 RUN apt-get update && apt-get install -y git \\ && rm -rf /var/lib/apt/lists/* WORKDIR /var/www/html/themes RUN git clone --branch 8 .x-3.x --single-branch --depth 1 https://git.drupal.org/project/bootstrap.git \\ && chown -R www-data:www-data bootstrap WORKDIR /var/www/html Then add this docker file to docker-compose 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 version : \"2\" services : drupal : image : custom-drupal build : . ports : - 8080:80 volumes : - modeuls:/var/www/html/modules - profiles:/var/www/html/profiles - themes:/var/www/html/themes - sites:/var/www/html/sites postgres : image : postgres:latest environment : - POSTGRES_PASSWORD=example volumes : - drupal-data:/var/lib/postgresql/data volumes : modeuls : profiles : themes : sites : drupal-data :","title":"Adding custom images to docker-compose files"},{"location":"docker-compose/","text":"What is it and why do we need it Configure relationships between containers Save docker container run settings in one file Comprised of 2 seperate, but related things: YAML file that descibes the containers, networks & volumes. The CLI tool Assignment: Writing your first docker compose for a Drupal CMS along with Postgres 1 2 3 4 5 6 7 8 9 10 11 12 version : \"3\" services : drupal : image : drupal:7.69-fpm-alpine ports : - 1111:80 postgres : image : postgres:10 environment : POSTGRES_PASSWORD : example","title":"Docker compose"},{"location":"docker-compose/#what-is-it-and-why-do-we-need-it","text":"Configure relationships between containers Save docker container run settings in one file Comprised of 2 seperate, but related things: YAML file that descibes the containers, networks & volumes. The CLI tool Assignment: Writing your first docker compose for a Drupal CMS along with Postgres 1 2 3 4 5 6 7 8 9 10 11 12 version : \"3\" services : drupal : image : drupal:7.69-fpm-alpine ports : - 1111:80 postgres : image : postgres:10 environment : POSTGRES_PASSWORD : example","title":"What is it and why do we need it"},{"location":"named-volumes-upgrades/","text":"Using Named Volumes in Upgrades Basic Idea We want to upgrade Postgres from 9.6.1 to 9.6.2 but retail all the data. In order to do this we will have a named volume which we will reassign to the new container Lets define a few things: name = first-postgres password = mysecretpassword database = roan volume = ../psql-data image = postgres:9.6.1-alpine 1 docker run --name first-postgres -e POSTGRES_PASSWORD = mysecretpassword -e POSTGRES_DB = roan -v /home/roan/Documents/docs/udemy-docker/psql-data:/var/lib/postgresql/data -d postgres:9.6.1-alpine Once the container has been created, connect to the container and log into postgres by running: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 docker exec -it first-postgres /bin/sh psql -U postgres # confirm database version postgres = # select version(); --------version--------- PostgreSQL 9 .6.1 on x86_64-pc-linux-gnu, compiled by gcc ( Alpine 6 .2.1 ) 6 .2.1 ( 1 row ) # list all databases postgres = # \\l List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------+----------+----------+------------+------------+----------------------- postgres | postgres | UTF8 | en_US.utf8 | en_US.utf8 | roan | postgres | UTF8 | en_US.utf8 | en_US.utf8 | ... # use database named roan and check table structure postgres = # \\c roan You are now connected to database \"roan\" as user \"postgres\" . roan = # \\d No relations found. # create table roan = # create table testing (name varchar(50)); CREATE TABLE roan = # \\d List of relations Schema | Name | Type | Owner --------+---------+-------+---------- public | testing | table | postgres ( 1 row ) Now, we have a database with some changes made. Next is to stop the container, remove it, replace it with a newer version and link it to the old data We will use the same docker run command as above, but just up the version and change the name to second-postgres 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # first stop the container docker stop first-postgres docker rm first-postgres docker run --name second-postgres -e POSTGRES_PASSWORD = mysecretpassword -e POSTGRES_DB = roan -v /home/roan/Documents/docs/udemy-docker/psql-data:/var/lib/postgresql/data -d postgres:9.6.2-alpine docker exec -it second-postgres /bin/sh psql -U postgres # check version postgres = # select version(); --------version-------- PostgreSQL 9 .6.2 on x86_64-pc-linux-musl, compiled by gcc ( Alpine 6 .2.1 ) 6 .2.1 ( 1 row ) # confirm the table created above is still there postgres = # \\c roan You are now connected to database \"roan\" as user \"postgres\" . roan = # \\d List of relations Schema | Name | Type | Owner --------+---------+-------+---------- public | testing | table | postgres ( 1 row )","title":"Named Volume Upgrades"},{"location":"named-volumes-upgrades/#using-named-volumes-in-upgrades","text":"","title":"Using Named Volumes in Upgrades"},{"location":"named-volumes-upgrades/#basic-idea","text":"We want to upgrade Postgres from 9.6.1 to 9.6.2 but retail all the data. In order to do this we will have a named volume which we will reassign to the new container Lets define a few things: name = first-postgres password = mysecretpassword database = roan volume = ../psql-data image = postgres:9.6.1-alpine 1 docker run --name first-postgres -e POSTGRES_PASSWORD = mysecretpassword -e POSTGRES_DB = roan -v /home/roan/Documents/docs/udemy-docker/psql-data:/var/lib/postgresql/data -d postgres:9.6.1-alpine Once the container has been created, connect to the container and log into postgres by running: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 docker exec -it first-postgres /bin/sh psql -U postgres # confirm database version postgres = # select version(); --------version--------- PostgreSQL 9 .6.1 on x86_64-pc-linux-gnu, compiled by gcc ( Alpine 6 .2.1 ) 6 .2.1 ( 1 row ) # list all databases postgres = # \\l List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------+----------+----------+------------+------------+----------------------- postgres | postgres | UTF8 | en_US.utf8 | en_US.utf8 | roan | postgres | UTF8 | en_US.utf8 | en_US.utf8 | ... # use database named roan and check table structure postgres = # \\c roan You are now connected to database \"roan\" as user \"postgres\" . roan = # \\d No relations found. # create table roan = # create table testing (name varchar(50)); CREATE TABLE roan = # \\d List of relations Schema | Name | Type | Owner --------+---------+-------+---------- public | testing | table | postgres ( 1 row ) Now, we have a database with some changes made. Next is to stop the container, remove it, replace it with a newer version and link it to the old data We will use the same docker run command as above, but just up the version and change the name to second-postgres 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # first stop the container docker stop first-postgres docker rm first-postgres docker run --name second-postgres -e POSTGRES_PASSWORD = mysecretpassword -e POSTGRES_DB = roan -v /home/roan/Documents/docs/udemy-docker/psql-data:/var/lib/postgresql/data -d postgres:9.6.2-alpine docker exec -it second-postgres /bin/sh psql -U postgres # check version postgres = # select version(); --------version-------- PostgreSQL 9 .6.2 on x86_64-pc-linux-musl, compiled by gcc ( Alpine 6 .2.1 ) 6 .2.1 ( 1 row ) # confirm the table created above is still there postgres = # \\c roan You are now connected to database \"roan\" as user \"postgres\" . roan = # \\d List of relations Schema | Name | Type | Owner --------+---------+-------+---------- public | testing | table | postgres ( 1 row )","title":"Basic Idea"},{"location":"swarm/","text":"Docker Swarm Introduction Swarm is the built in orchestration clustering withing Docker Since Swarm is not active by default, you can enable it by running: docker swarm init In the event the you have more than more than one network on defined in ip a , specify the main network you use, in this case: 1 2 3 4 5 6 7 8 9 10 docker swarm init --advertise-addr enp0s3 # output Swarm initialized: current node ( qe1qz7v5n8rm4n16q9dgt10t4 ) is now a manager. To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-4rl65f229t816t6sznyc2z93gdjxyti4ji3fklimm6kz5ohkzm-9es80g8s5y3yndl4qlybrd35m 10 .0.2.15:2377 To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. What has happened is that Docker created a root signing certificate for the Swarm and issued it to the first manager (the docker machine you just enabled swarm on). It also create join tokens to be used by worker nodes Check the docker nodes: 1 2 3 4 5 docker node ls # output ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION qe1qz7v5n8rm4n16q9dgt10t4 * manjaro-main Ready Active Leader 19 .03.5-ce Creating a new Swarm Service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 # create an alpine service docker service create alpine ping 8 .8.8.8 mvgc5gc0pspzv3qqfgi5dwib1 overall progress: 1 out of 1 tasks 1 /1: running verify: Service converged # list running services docker service ls ID NAME MODE REPLICAS IMAGE PORTS mvgc5gc0pspz elastic_sinoussi replicated 1 /1 alpine:latest # inspect the service docker service ps elastic_sinoussi ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS njly65bet6yl elastic_sinoussi.1 alpine:latest manjaro-main Running Running 38 seconds ago # update the service docker service update elastic_sinoussi --replicas 3 elastic_sinoussi overall progress: 3 out of 3 tasks 1 /3: running 2 /3: running 3 /3: running verify: Service converged # view updated service docker service ps elastic_sinoussi ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS njly65bet6yl elastic_sinoussi.1 alpine:latest manjaro-main Running Running 23 minutes ago dzfqp3o3apkp elastic_sinoussi.2 alpine:latest manjaro-main Running Running 13 minutes ago tqfyxt625523 elastic_sinoussi.3 alpine:latest manjaro-main Running Running 13 minutes ago # lets remove one of the containers manaully docker container rm -f elastic_sinoussi.1.njly65bet6ylamk7c6dco53i8 # if we then check the docker service, we will notice that it has already identified a container was killed and automatically spun up a new one docker service ps elastic_sinoussi ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS kzu8tncudoje elastic_sinoussi.1 alpine:latest manjaro-main Running Running 24 seconds ago njly65bet6yl \\_ elastic_sinoussi.1 alpine:latest manjaro-main Shutdown Failed 30 seconds ago \"task: non-zero exit (137)\" dzfqp3o3apkp elastic_sinoussi.2 alpine:latest manjaro-main Running Running 24 minutes ago tqfyxt625523 elastic_sinoussi.3 alpine:latest manjaro-main Running Running 24 minutes ago # lastly, remove the service docker service rm elastic_sinoussi","title":"Docker Swarm"},{"location":"swarm/#docker-swarm-introduction","text":"Swarm is the built in orchestration clustering withing Docker Since Swarm is not active by default, you can enable it by running: docker swarm init In the event the you have more than more than one network on defined in ip a , specify the main network you use, in this case: 1 2 3 4 5 6 7 8 9 10 docker swarm init --advertise-addr enp0s3 # output Swarm initialized: current node ( qe1qz7v5n8rm4n16q9dgt10t4 ) is now a manager. To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-4rl65f229t816t6sznyc2z93gdjxyti4ji3fklimm6kz5ohkzm-9es80g8s5y3yndl4qlybrd35m 10 .0.2.15:2377 To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. What has happened is that Docker created a root signing certificate for the Swarm and issued it to the first manager (the docker machine you just enabled swarm on). It also create join tokens to be used by worker nodes Check the docker nodes: 1 2 3 4 5 docker node ls # output ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION qe1qz7v5n8rm4n16q9dgt10t4 * manjaro-main Ready Active Leader 19 .03.5-ce","title":"Docker Swarm Introduction"},{"location":"swarm/#creating-a-new-swarm-service","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 # create an alpine service docker service create alpine ping 8 .8.8.8 mvgc5gc0pspzv3qqfgi5dwib1 overall progress: 1 out of 1 tasks 1 /1: running verify: Service converged # list running services docker service ls ID NAME MODE REPLICAS IMAGE PORTS mvgc5gc0pspz elastic_sinoussi replicated 1 /1 alpine:latest # inspect the service docker service ps elastic_sinoussi ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS njly65bet6yl elastic_sinoussi.1 alpine:latest manjaro-main Running Running 38 seconds ago # update the service docker service update elastic_sinoussi --replicas 3 elastic_sinoussi overall progress: 3 out of 3 tasks 1 /3: running 2 /3: running 3 /3: running verify: Service converged # view updated service docker service ps elastic_sinoussi ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS njly65bet6yl elastic_sinoussi.1 alpine:latest manjaro-main Running Running 23 minutes ago dzfqp3o3apkp elastic_sinoussi.2 alpine:latest manjaro-main Running Running 13 minutes ago tqfyxt625523 elastic_sinoussi.3 alpine:latest manjaro-main Running Running 13 minutes ago # lets remove one of the containers manaully docker container rm -f elastic_sinoussi.1.njly65bet6ylamk7c6dco53i8 # if we then check the docker service, we will notice that it has already identified a container was killed and automatically spun up a new one docker service ps elastic_sinoussi ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS kzu8tncudoje elastic_sinoussi.1 alpine:latest manjaro-main Running Running 24 seconds ago njly65bet6yl \\_ elastic_sinoussi.1 alpine:latest manjaro-main Shutdown Failed 30 seconds ago \"task: non-zero exit (137)\" dzfqp3o3apkp elastic_sinoussi.2 alpine:latest manjaro-main Running Running 24 minutes ago tqfyxt625523 elastic_sinoussi.3 alpine:latest manjaro-main Running Running 24 minutes ago # lastly, remove the service docker service rm elastic_sinoussi","title":"Creating a new Swarm Service"}]}